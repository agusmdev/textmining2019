{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesIterator:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.path, 'r') as f:\n",
    "            for l in f.readlines()[:3000]:\n",
    "                yield l.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = SentencesIterator('clean_corpus/spanish_billion_words/spanish_billion_words_48')\n",
    "sents = list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "   (?:\\d{1,3}(?:\\.\\d{3})+)  # numbers with '.' in the middle\n",
    "   | (?:[Ss]r\\.|[Ss]ra\\.|art\\.)  # common spanish abbreviations\n",
    "   | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''\n",
    "tokenizer = RegexpTokenizer(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(pattern)\n",
    "sents = [tokenizer.tokenize(' '.join(sent)) for sent in sents]\n",
    "# sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    return [word.lower() for word in words] \n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('spanish'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "# words = normalize(words)\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "from tqdm import tqdm\n",
    "lemma_sents = [lemmatize_verbs(sent) for sent in sents]\n",
    "# print('Stemmed:\\n', stems)\n",
    "# print('\\nLemmatized:\\n', lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents3=['-\\n\"Lo que sostiene a la pareja es el amor\"\\nClara Crespo (50) y Rodolfo Martínez (54) no se imaginan uno sin el otro.', '\"Prefiero ni pensarlo\", dice Clara.', 'Hace 26 años que están casados, y tienen cuatro hijas mujeres.', 'Se conocieron en el Ateneo Juventus, el movimiento juvenil de Capuchinos.', 'Hoy aseguran no estar sorprendidos del tiempo que llevan juntos sino de haber logrado entenderse tan bien.', '&#226;&#8364;&#8220;¿Qué les gusta y disgusta del otro?', '¿Qué quisieran cambiarle?', '&#226;&#8364;&#8220;Rodolfo: Me gusta que sea cariñosa, alegre y esté siempre pensando en mí, y que es una gran madre.', 'Me disgustaba que cuando se enojaba no quería hablar, pero ya no lo hace más.', 'A veces es indecisa pero ya me acostumbré.', 'No quiero cambiarle nada, que sea como es.', '&#226;&#8364;&#8220;Clara : Me gusta que es una persona emprendedora, alegre, optimista y servicial.', 'Me gustaría que a veces fuera más sutil para decir las cosas.', 'Pienso que las personas vamos cambiando con el tiempo de acuerdo a la edad, a las circunstancias que vivimos y todo lo que nos rodea.', 'Seguramente que no somos los mismos que cuando nos casamos y siempre seguiremos descubriendo cosas nuevas del otro.', 'Lo bueno es conversar y ayudarse a cambiar esas cosas que molestan al otro.', '&#226;&#8364;&#8220;¿Cuál fue el momento más difícil?', '-C: Sin duda fue cuando perdimos una hija.', 'Después de un dolor tan grande uno ve la vida de otra manera y ningún problema te parece tan grande.', 'Lo que más nos ayudó es que los dos compartimos la misma fe en Dios y sólo a través de &#195;&#8240;l podes darle otro sentido a la muerte.', 'También cuando vivimos separados un año y medio, por razones de trabajo de Rody.', 'Clara asegura que lo que sostiene a la pareja es el amor.', '\"Hay que alimentarlo para que crezca siempre.', 'Los proyectos y objetivos en común también ayudan a tener ilusiones y ganas de seguir juntos, pero todo es inútil si no hay amor.', 'Hay que tratar de crecer en todos los aspectos en forma permanente\".', '&#226;&#8364;&#8220;Un matrimonio a largo plazo, ¿es un refugio contra inseguridades, una rareza, un triunfo, orgullo?', '&#226;&#8364;&#8220;R: Es un medio para ser feliz, un proyecto de vida.', '&#226;&#8364;&#8220;C: Es una hermosa experiencia, más que todo eso.', 'El triunfo es ir logrando quererse cada día más.', '&#226;&#8364;&#8220;¿Por qué ahora las parejas duran menos?', '&#226;&#8364;&#8220;C: Creo que puede faltar comunicación y a veces proyecto y objetivos en común.', 'Cuando uno elige la vida de a dos a veces tiene que dejar de lado o postergar intereses personales.', '-¿Los recursos económicos son un conflicto?', '&#226;&#8364;&#8220;R: No son un problema, aunque a veces no había suficiente nunca fue una prioridad.', 'En general lo manejamos juntos, aunque el día a día lo lleva Clara.', '&#226;&#8364;&#8220;C: Siempre pusimos en común los ingresos cuando los dos trabajábamos.', 'Todo es de los dos.', '¡Menos mal, sino ahora que no trabajo estaría chau!', 'Y nos ponemos de acuerdo en la forma de administrarlo.', '&#226;&#8364;&#8220;¿La pasión es el secreto de la duración feliz?', 'R: La pasión es necesaria, pero no es el secreto de la felicidad.', 'Es importante mantener la pasión de los primeros años, toda la vida.', '-\\nEl Carbó y el Ipem 270 levantaron la toma\\nLos secundarios Ipem 270 Manuel Belgrano y Alejandro Carbó decidieron ayer levantar la toma de las instituciones escolares.', 'Así, se sumaron a la medida que ya había tomado el Jerónimo Luis de Cabrera el sábado.', 'Estos tres colegios habían iniciado la toma el miércoles 29 de septiembre en reclamo de mejoras edilicias y pidiendo que se discuta el anteproyecto de reforma de la ley de Educación.', 'El sábado, suscribieron un acuerdo con el Ministerio de Educación por el que levantaban las tomas a cambio de planes de obras de las y una instancia de debate para la normativa.', '\"Si el Gobierno nos toma el pelo, volveremos a las tomas\", advirtieron desde Secundarios Unidos de Córdoba, que aglutina a los centros de estudiantes de esas escuelas, al tiempo que calificaron lo logrado como \"una victoria\".', '\"Que sepan que cada día somos más y más colegios los que abrimos los ojos para luchar día a día por una educación para todos y todas\", agregan.', 'También firmaron el acuerdo el Deán Funes, el Nicolás Copérnico y el Ipem 16 de Villa Cornú, que en principio levantarían las tomas entre martes y miércoles, cuando lleguen los planes de obras.', 'No obstante, desde el grupo que mantiene las medidas de fuerza por el reclamo de la ley de Educación pusieron en duda esa posibilidad.', 'Ese grupo, denominado Coordinadora Interestudiantil, también volvió a llamar a la unidad del movimiento estudiantil.', '\"Convocamos a las escuelas que han firmado el acta porque se han empezado algunos de los planes de refacción a continuar las luchas\", sostuvieron.', '-\\n\"Tenemos una familia hermosa, qué más pedir\"\\nPedro (78) y Mary (74) parecen estar viviendo una luna de miel, pero llevan 51 años casados.', 'Pedro la trata como a una reina, de vez en cuando le compra bombones o la sorprende con una carta que algún locutor lee en la radio.', 'La llama \"Gordita\" a cada rato, la abraza y se ríen.', 'No han tenido una vida fácil, dicen.', 'Pero agradecen lo que les ha dado: cinco hijos (uno murió) y 13 nietos.', '\"Estamos juntos hace más de 21 mil días.', 'Hace 59 años que estamos de novios\", comenta con precisión Pedro Rodríguez, en su casa de barrio Ayacucho.', 'En la entrada del hogar que habitan hace 46 años, hay una Virgen y una leyenda que anticipa los cimientos con los que se construyó este hogar.', 'Dice más o menos así: \"Somos Pedro y Mary.', 'Tenemos una familia hermosa, qué más podemos pedir\".', 'Mary es María Isabel Barrionuevo, ex empleada de la Fábrica Militar de Aviones.', 'La mujer cuenta que se conocieron a los 13 años y todo lo que vino después.', 'La charla es tan amena que el agua para el café se consume por completo.', '\"Nada que ver con las relaciones de ahora.', 'A los dos meses de estar de novios, recién me dio el primer beso.', 'Yo lo paraba en seco\", recuerda Mary.', 'Sin embargo no cree que el tiempo pasado haya sido mejor.', '\"Había muchos tabúes\".', '&#226;&#8364;&#8220;¿Se imaginaron que iban a durar tanto tiempo?', '&#226;&#8364;&#8220;Uno no tuvo tiempo de analizar.', 'Nos casamos enamorados.', '¡No sabés lo que fue la luna de miel!', '¡Salir de noche solos!', 'Nunca habíamos salido solos&#226;&#8364;&#8220;, dice Mary, entre risas.', 'Coinciden en que son muy compañeros y saben conversar.', 'Todo lo hacen juntos.', '\"Pobrecito el que se quede cuando el otro desaparezca\", reflexiona Pedro, ex empleado de Entel.', '\"Mi madre me decía siempre que cuando en una discusión uno está nervioso, el otro se debe callar.', 'Hay que esperar que pare la tormenta y después hablar.', 'A nosotros nos ayudó\", aconseja Mary.', 'Pedro asegura que no han tenido tiempo para peleas; si había discusiones, era por los hijos.', '\"A veces uno salía en defensa de uno o de otro\", admiten.', 'Creen que los momentos más difíciles fueron los comienzos.', 'Los otros avatares de la vida los unió más.', '&#226;&#8364;&#8220;¿Qué les gusta del otro?', '&#226;&#8364;&#8220;&#195;&#8240;l es muy noble, honesto, siempre está tratando de ayudar, es sencillo y generoso, dice Mary, con mucha seguridad.', 'Pedro la mira, y responde: \"Me gusta todo, es inigualable\".', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "sents2 = [pos_tag(word_tokenize(sent)) for sent in sents3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_dict(base_feats, nf, sent, i):\n",
    "    feat_dict = {}\n",
    "    for n in range(0, nf + 1):\n",
    "        for feature, fun in base_feats.items():\n",
    "            prev = \"p\"*n\n",
    "            nxt = \"n\"*n\n",
    "            if len(sent) <= n + i:\n",
    "                continue\n",
    "            feat_dict[prev + feature] = fun(sent[i-n])\n",
    "            feat_dict[nxt + feature] = fun(sent[i+n])\n",
    "\n",
    "    return feat_dict\n",
    "\n",
    "\n",
    "def feature_dict(sent, i, n=3):\n",
    "    # n must be odd\n",
    "    if n % 2 != 1:\n",
    "        n -= 1\n",
    "\n",
    "    if \"<s>\" not in sent:\n",
    "        sent = [\"<s>\"] + list(sent) + [\"</s>\"]\n",
    "        i += 1\n",
    "\n",
    "    n_feats = int(n/2)\n",
    "\n",
    "    base_feats = {\n",
    "            \"w\": str.lower,\n",
    "            \"wu\": str.isupper,\n",
    "            \"wt\": str.istitle,\n",
    "            \"wd\": str.isdigit,\n",
    "        }\n",
    "\n",
    "    return make_feature_dict(base_feats, n_feats, sent, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = []\n",
    "features = []\n",
    "for sent in sents2:\n",
    "    for i, (fst, snd) in enumerate(sent):\n",
    "        new_stuff_dict = feature_dict()\n",
    "        features.append(new_stuff_dict)\n",
    "        check_list.append(fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=True)\n",
    "X = v.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1647x576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4941 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = v.inverse_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.30140056e-15, -1.27194493e-14,  2.30552124e-15, ...,\n",
       "         2.14722387e-03, -4.19240582e-04,  2.52716197e-04],\n",
       "       [ 1.68415460e-16,  2.32322051e-15, -1.49428344e-15, ...,\n",
       "        -6.67346902e-12, -2.71887895e-14, -1.10195775e-12],\n",
       "       [ 1.51029456e-02,  1.68153732e-02,  1.37435387e-14, ...,\n",
       "        -1.91517363e-03,  8.92896837e-03,  1.39674278e-02],\n",
       "       ...,\n",
       "       [ 1.68431321e-16,  3.05719468e-17,  2.05335165e-16, ...,\n",
       "        -6.67353163e-12, -2.73215076e-14, -1.10212431e-12],\n",
       "       [-1.25048762e-16,  2.06024294e-14,  1.41155365e+00, ...,\n",
       "         7.96165703e-04,  1.53135684e-04, -1.47149179e-03],\n",
       "       [ 2.98838002e-15,  4.40963587e-15,  2.50578602e-15, ...,\n",
       "         2.14722387e-03, -4.19240582e-04,  2.52716197e-04]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=78, n_iter=7, random_state=42)\n",
    "svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=40, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=40)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 22,  7, ..., 22,  3, 37], dtype=int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{37: {'-'},\n",
       " 22: {\"''\"},\n",
       " 7: {')',\n",
       "  'Alejandro',\n",
       "  'Así',\n",
       "  'Ateneo',\n",
       "  'Aviones',\n",
       "  'Ayacucho',\n",
       "  'Barrionuevo',\n",
       "  'Belgrano',\n",
       "  'C',\n",
       "  'Cabrera',\n",
       "  'Capuchinos',\n",
       "  'Carbó',\n",
       "  'Clara',\n",
       "  'Coinciden',\n",
       "  'Convocamos',\n",
       "  'Coordinadora',\n",
       "  'Copérnico',\n",
       "  'Cornú',\n",
       "  'Creen',\n",
       "  'Creo',\n",
       "  'Crespo',\n",
       "  'Cuando',\n",
       "  'Córdoba',\n",
       "  'Después',\n",
       "  'Deán',\n",
       "  'Dice',\n",
       "  'Dios',\n",
       "  'Educación',\n",
       "  'El',\n",
       "  'En',\n",
       "  'Entel',\n",
       "  'Es',\n",
       "  'Ese',\n",
       "  'Estamos',\n",
       "  'Estos',\n",
       "  'Funes',\n",
       "  'Fábrica',\n",
       "  'Gobierno',\n",
       "  'Gordita',\n",
       "  'Había',\n",
       "  'Hace',\n",
       "  'Hay',\n",
       "  'Hoy',\n",
       "  'Interestudiantil',\n",
       "  'Ipem',\n",
       "  'Isabel',\n",
       "  'Jerónimo',\n",
       "  'Juventus',\n",
       "  'La',\n",
       "  'Lo',\n",
       "  'Los',\n",
       "  'Luis',\n",
       "  'Manuel',\n",
       "  'Martínez',\n",
       "  'Mary',\n",
       "  'María',\n",
       "  'Me',\n",
       "  'Mi',\n",
       "  'Militar',\n",
       "  'Ministerio',\n",
       "  'Nada',\n",
       "  'Nicolás',\n",
       "  'Nos',\n",
       "  'Nunca',\n",
       "  'Pero',\n",
       "  'Pienso',\n",
       "  'Pobrecito',\n",
       "  'Prefiero',\n",
       "  'Que',\n",
       "  'R',\n",
       "  'Rodolfo',\n",
       "  'Rodríguez',\n",
       "  'Rody',\n",
       "  'Se',\n",
       "  'Secundarios',\n",
       "  'Seguramente',\n",
       "  'Si',\n",
       "  'Siempre',\n",
       "  'Sin',\n",
       "  'Somos',\n",
       "  'También',\n",
       "  'Tenemos',\n",
       "  'Todo',\n",
       "  'Un',\n",
       "  'Unidos',\n",
       "  'Uno',\n",
       "  'Villa',\n",
       "  'Virgen',\n",
       "  'Yo'},\n",
       " 35: {'Y', 'decidieron', 'que', 'y', '¿es'},\n",
       " 0: {'abraza',\n",
       "  'acuerdo',\n",
       "  'administrarlo',\n",
       "  'advirtieron',\n",
       "  'agregan',\n",
       "  'algunos',\n",
       "  'anteproyecto',\n",
       "  'aseguran',\n",
       "  'barrio',\n",
       "  'casa',\n",
       "  'defensa',\n",
       "  'desde',\n",
       "  'duración',\n",
       "  'edilicias',\n",
       "  'el',\n",
       "  'empezado',\n",
       "  'empleada',\n",
       "  'empleado',\n",
       "  'en',\n",
       "  'entrada',\n",
       "  'es',\n",
       "  'esas',\n",
       "  'estamos',\n",
       "  'estar',\n",
       "  'estudiantes',\n",
       "  'está',\n",
       "  'ex',\n",
       "  'forma',\n",
       "  'fue',\n",
       "  'fuerza',\n",
       "  'ganas',\n",
       "  'haber',\n",
       "  'habitan',\n",
       "  'hacen',\n",
       "  'imaginaron',\n",
       "  'lado',\n",
       "  'las',\n",
       "  'ley',\n",
       "  'llevan',\n",
       "  'los',\n",
       "  'luna',\n",
       "  'madre',\n",
       "  'medidas',\n",
       "  'mejoras',\n",
       "  'miel',\n",
       "  'misma',\n",
       "  'noche',\n",
       "  'normativa',\n",
       "  'novios',\n",
       "  'o',\n",
       "  'obras',\n",
       "  'otra',\n",
       "  'otro',\n",
       "  'pasión',\n",
       "  'planes',\n",
       "  'por',\n",
       "  'qué',\n",
       "  'recién',\n",
       "  'reclamo',\n",
       "  'recuerda',\n",
       "  'refacción',\n",
       "  'reflexiona',\n",
       "  'reforma',\n",
       "  'se',\n",
       "  'seguir',\n",
       "  'septiembre',\n",
       "  'si',\n",
       "  'sostiene',\n",
       "  'su',\n",
       "  'sólo',\n",
       "  'tiempo',\n",
       "  'toma',\n",
       "  'trabajo',\n",
       "  'un',\n",
       "  'uno',\n",
       "  'vez',\n",
       "  'vida',\n",
       "  'volveremos',\n",
       "  'volvió',\n",
       "  'y'},\n",
       " 15: {'A', 'a'},\n",
       " 14: {'la'},\n",
       " 1: {'-C',\n",
       "  'R',\n",
       "  'acta',\n",
       "  'acuerdo',\n",
       "  'agradecen',\n",
       "  'agua',\n",
       "  'ahora',\n",
       "  'al',\n",
       "  'alegre',\n",
       "  'algún',\n",
       "  'alimentarlo',\n",
       "  'amena',\n",
       "  'amor',\n",
       "  'analizar',\n",
       "  'asegura',\n",
       "  'aspectos',\n",
       "  'ayer',\n",
       "  'ayudar',\n",
       "  'ayudó',\n",
       "  'año',\n",
       "  'años',\n",
       "  'beso',\n",
       "  'bien',\n",
       "  'bueno',\n",
       "  'cada',\n",
       "  'café',\n",
       "  'calificaron',\n",
       "  'callar',\n",
       "  'cambiando',\n",
       "  'cambiarle',\n",
       "  'cambio',\n",
       "  'cariñosa',\n",
       "  'carta',\n",
       "  'casados',\n",
       "  'casamos',\n",
       "  'centros',\n",
       "  'charla',\n",
       "  'chau',\n",
       "  'cinco',\n",
       "  'circunstancias',\n",
       "  'comienzos',\n",
       "  'como',\n",
       "  'compartimos',\n",
       "  'compañeros',\n",
       "  'completo',\n",
       "  'compra',\n",
       "  'comunicación',\n",
       "  'común',\n",
       "  'con',\n",
       "  'conflicto',\n",
       "  'conocieron',\n",
       "  'construyó',\n",
       "  'consume',\n",
       "  'continuar',\n",
       "  'contra',\n",
       "  'conversar',\n",
       "  'cosas',\n",
       "  'crecer',\n",
       "  'crezca',\n",
       "  'cuatro',\n",
       "  'cuenta',\n",
       "  'dado',\n",
       "  'debate',\n",
       "  'debe',\n",
       "  'decir',\n",
       "  'dejar',\n",
       "  'del',\n",
       "  'denominado',\n",
       "  'desaparezca',\n",
       "  'descubriendo',\n",
       "  'desde',\n",
       "  'después',\n",
       "  'dice',\n",
       "  'dicen',\n",
       "  'difícil',\n",
       "  'discusión',\n",
       "  'discuta',\n",
       "  'disgusta',\n",
       "  'disgustaba',\n",
       "  'dolor',\n",
       "  'dos',\n",
       "  'duda',\n",
       "  'durar',\n",
       "  'día',\n",
       "  'días',\n",
       "  'económicos',\n",
       "  'edad',\n",
       "  'educación',\n",
       "  'elige',\n",
       "  'emprendedora',\n",
       "  'en',\n",
       "  'enamorados',\n",
       "  'entenderse',\n",
       "  'entre',\n",
       "  'era',\n",
       "  'esa',\n",
       "  'esas',\n",
       "  'escuelas',\n",
       "  'eso',\n",
       "  'esperar',\n",
       "  'estar',\n",
       "  'este',\n",
       "  'estudiantil',\n",
       "  'está',\n",
       "  'están',\n",
       "  'esté',\n",
       "  'experiencia',\n",
       "  'faltar',\n",
       "  'familia',\n",
       "  'fe',\n",
       "  'felicidad',\n",
       "  'feliz',\n",
       "  'firmado',\n",
       "  'firmaron',\n",
       "  'forma',\n",
       "  'fue',\n",
       "  'fuera',\n",
       "  'fácil',\n",
       "  'generoso',\n",
       "  'gran',\n",
       "  'grande',\n",
       "  'grupo',\n",
       "  'gusta',\n",
       "  'gustaría',\n",
       "  'hablar',\n",
       "  'había',\n",
       "  'habíamos',\n",
       "  'habían',\n",
       "  'hace',\n",
       "  'han',\n",
       "  'hay',\n",
       "  'haya',\n",
       "  'hermosa',\n",
       "  'hija',\n",
       "  'hijas',\n",
       "  'hijos',\n",
       "  'hogar',\n",
       "  'honesto',\n",
       "  'iban',\n",
       "  'imaginan',\n",
       "  'importante',\n",
       "  'instancia',\n",
       "  'inútil',\n",
       "  'ir',\n",
       "  'juvenil',\n",
       "  'largo',\n",
       "  'las',\n",
       "  'le',\n",
       "  'lee',\n",
       "  'levantar',\n",
       "  'levantaron',\n",
       "  'levantarían',\n",
       "  'leyenda',\n",
       "  'llamar',\n",
       "  'lleguen',\n",
       "  'lleva',\n",
       "  'llevan',\n",
       "  'lo',\n",
       "  'locutor',\n",
       "  'logrado',\n",
       "  'los',\n",
       "  'luchar',\n",
       "  'luchas',\n",
       "  'luna',\n",
       "  'madre',\n",
       "  'manejamos',\n",
       "  'manera',\n",
       "  'mantener',\n",
       "  'mantiene',\n",
       "  'medida',\n",
       "  'medio',\n",
       "  'mejor',\n",
       "  'mira',\n",
       "  'mismos',\n",
       "  'molestan',\n",
       "  'momento',\n",
       "  'momentos',\n",
       "  'movimiento',\n",
       "  'mucha',\n",
       "  'muchos',\n",
       "  'muerte',\n",
       "  'murió',\n",
       "  'muy',\n",
       "  'mí',\n",
       "  'nada',\n",
       "  'nervioso',\n",
       "  'ni',\n",
       "  'nietos',\n",
       "  'o',\n",
       "  'objetivos',\n",
       "  'obstante',\n",
       "  'orgullo',\n",
       "  'otro',\n",
       "  'para',\n",
       "  'pare',\n",
       "  'parece',\n",
       "  'parecen',\n",
       "  'pareja',\n",
       "  'pasado',\n",
       "  'pedir',\n",
       "  'pelo',\n",
       "  'pensando',\n",
       "  'pensarlo',\n",
       "  'perdimos',\n",
       "  'permanente',\n",
       "  'persona',\n",
       "  'pidiendo',\n",
       "  'plazo',\n",
       "  'podemos',\n",
       "  'ponemos',\n",
       "  'por',\n",
       "  'porque',\n",
       "  'posibilidad',\n",
       "  'postergar',\n",
       "  'precisión',\n",
       "  'primer',\n",
       "  'principio',\n",
       "  'prioridad',\n",
       "  'problema',\n",
       "  'proyecto',\n",
       "  'proyectos',\n",
       "  'puede',\n",
       "  'pusieron',\n",
       "  'quererse',\n",
       "  'quería',\n",
       "  'quiero',\n",
       "  'quisieran',\n",
       "  'radio',\n",
       "  'rareza',\n",
       "  'rato',\n",
       "  'recursos',\n",
       "  'refugio',\n",
       "  'reina',\n",
       "  'responde',\n",
       "  'risas',\n",
       "  'rodea',\n",
       "  'ríen',\n",
       "  'saben',\n",
       "  'sabés',\n",
       "  'salido',\n",
       "  'sea',\n",
       "  'seco',\n",
       "  'secreto',\n",
       "  'seguiremos',\n",
       "  'seguridad',\n",
       "  'sencillo',\n",
       "  'sentido',\n",
       "  'sepan',\n",
       "  'separados',\n",
       "  'ser',\n",
       "  'servicial',\n",
       "  'sido',\n",
       "  'siempre',\n",
       "  'sin',\n",
       "  'sino',\n",
       "  'solos',\n",
       "  'somos',\n",
       "  'son',\n",
       "  'sostuvieron',\n",
       "  'suscribieron',\n",
       "  'sutil',\n",
       "  'sábado',\n",
       "  'tabúes',\n",
       "  'también',\n",
       "  'tan',\n",
       "  'tanto',\n",
       "  'te',\n",
       "  'tener',\n",
       "  'tiempo',\n",
       "  'tiene',\n",
       "  'todas',\n",
       "  'todo',\n",
       "  'todos',\n",
       "  'toma',\n",
       "  'tomado',\n",
       "  'tomas',\n",
       "  'trabajo',\n",
       "  'trabajábamos',\n",
       "  'trata',\n",
       "  'tratando',\n",
       "  'tratar',\n",
       "  'través',\n",
       "  'triunfo',\n",
       "  've',\n",
       "  'victoria',\n",
       "  'vida',\n",
       "  'vino',\n",
       "  'viviendo',\n",
       "  'vivimos',\n",
       "  'ya',\n",
       "  '¡Salir',\n",
       "  '¿Qué'},\n",
       " 23: {'es'},\n",
       " 21: {'('},\n",
       " 8: {'13',\n",
       "  '16',\n",
       "  '195',\n",
       "  '21',\n",
       "  '26',\n",
       "  '270',\n",
       "  '29',\n",
       "  '46',\n",
       "  '50',\n",
       "  '51',\n",
       "  '54',\n",
       "  '59',\n",
       "  '74',\n",
       "  '78',\n",
       "  '8220',\n",
       "  '8240'},\n",
       " 18: {'y'},\n",
       " 11: {'No', 'aconseja', 'no'},\n",
       " 5: {'-¿Los',\n",
       "  'acuerdo',\n",
       "  'ahora',\n",
       "  'alegre',\n",
       "  'aunque',\n",
       "  'años',\n",
       "  'cambiar',\n",
       "  'comenta',\n",
       "  'con',\n",
       "  'cree',\n",
       "  'decía',\n",
       "  'dice',\n",
       "  'dio',\n",
       "  'dos',\n",
       "  'duran',\n",
       "  'el',\n",
       "  'entre',\n",
       "  'es',\n",
       "  'fue',\n",
       "  'general',\n",
       "  'gusta',\n",
       "  'ha',\n",
       "  'indecisa',\n",
       "  'ingresos',\n",
       "  'inigualable',\n",
       "  'la',\n",
       "  'las',\n",
       "  'levantaban',\n",
       "  'lo',\n",
       "  'logrado',\n",
       "  'logrando',\n",
       "  'los',\n",
       "  'mal',\n",
       "  'movimiento',\n",
       "  'ningún',\n",
       "  'noble',\n",
       "  'nos',\n",
       "  'nosotros',\n",
       "  'nuevas',\n",
       "  'nunca',\n",
       "  'ojos',\n",
       "  'optimista',\n",
       "  'otro',\n",
       "  'otros',\n",
       "  'paraba',\n",
       "  'por',\n",
       "  'que',\n",
       "  'qué',\n",
       "  'salía',\n",
       "  'se',\n",
       "  'siempre',\n",
       "  'sino',\n",
       "  'somos',\n",
       "  'sorprende',\n",
       "  'tan',\n",
       "  'tiempo',\n",
       "  'tienen',\n",
       "  'toda',\n",
       "  'tomas',\n",
       "  'tormenta',\n",
       "  'tuvo',\n",
       "  'un',\n",
       "  'unidad',\n",
       "  'unió',\n",
       "  'uno',\n",
       "  'vamos',\n",
       "  'y',\n",
       "  '¡No'},\n",
       " 28: {'El', 'el'},\n",
       " 3: {'!', '.', '?'},\n",
       " 24: {'``'},\n",
       " 2: {','},\n",
       " 9: {'que'},\n",
       " 26: {'abrimos',\n",
       "  'avatares',\n",
       "  'bombones',\n",
       "  'cimientos',\n",
       "  'colegios',\n",
       "  'discusiones',\n",
       "  'escolares',\n",
       "  'escuelas',\n",
       "  'ilusiones',\n",
       "  'inseguridades',\n",
       "  'instituciones',\n",
       "  'intereses',\n",
       "  'las',\n",
       "  'martes',\n",
       "  'menos',\n",
       "  'meses',\n",
       "  'mil',\n",
       "  'miércoles',\n",
       "  'mujeres',\n",
       "  'necesaria',\n",
       "  'peleas',\n",
       "  'personales',\n",
       "  'planes',\n",
       "  'podes',\n",
       "  'primeros',\n",
       "  'razones',\n",
       "  'relaciones',\n",
       "  'secundarios',\n",
       "  'veces',\n",
       "  '¡Menos'},\n",
       " 34: {'aunque',\n",
       "  'ayudan',\n",
       "  'ayudarse',\n",
       "  'difíciles',\n",
       "  'duda',\n",
       "  'día',\n",
       "  'el',\n",
       "  'embargo',\n",
       "  'enojaba',\n",
       "  'estaría',\n",
       "  'la',\n",
       "  'las',\n",
       "  'les',\n",
       "  'llama',\n",
       "  'lo',\n",
       "  'matrimonio',\n",
       "  'miércoles',\n",
       "  'mujer',\n",
       "  'que',\n",
       "  'se',\n",
       "  'si',\n",
       "  'sorprendidos',\n",
       "  'suficiente',\n",
       "  'tenido',\n",
       "  'tres',\n",
       "  'y'},\n",
       " 10: {'anticipa', 'de', 'en', 'ya'},\n",
       " 20: {'del'},\n",
       " 36: {'juntos'},\n",
       " 12: {'&', 'l', 'nos', '¿Cuál', '¿La', '¿Por', '¿Qué', '¿Se'},\n",
       " 6: {'#'},\n",
       " 39: {'226'},\n",
       " 4: {':', ';'},\n",
       " 30: {'8364'},\n",
       " 31: {'una'},\n",
       " 33: {'cuando'},\n",
       " 27: {'se'},\n",
       " 38: {'pero'},\n",
       " 16: {'más'},\n",
       " 32: {'me'},\n",
       " 17: {'acostumbré',\n",
       "  'aglutina',\n",
       "  'ahora',\n",
       "  'al',\n",
       "  'así',\n",
       "  'años',\n",
       "  'con',\n",
       "  'darle',\n",
       "  'iniciado',\n",
       "  'los',\n",
       "  'o',\n",
       "  'parejas',\n",
       "  'personas',\n",
       "  'proyecto',\n",
       "  'pusimos',\n",
       "  'quede',\n",
       "  'sumaron',\n",
       "  'tomas',\n",
       "  'y'},\n",
       " 13: {'de'},\n",
       " 25: {'admiten', 'fueron', 'un', 'ver'},\n",
       " 29: {'la'},\n",
       " 19: {'Pedro'}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "words = defaultdict(set)\n",
    "for i, label in enumerate(labels):\n",
    "    words[label].add(check_list[i])\n",
    "words = dict(words)\n",
    "# for key, value in words.items():\n",
    "#     print('CLuster:', key)\n",
    "#     print(list(value)[:10])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " w=que\n",
      " nw=a\n",
      " w=las\n",
      " pw=de\n",
      " pw=asimismo\n",
      " pw=problemas\n",
      " nw=un\n",
      " pw=recomendación\n",
      " nw=situación\n",
      " pw=resuelva\n",
      "Cluster 1:\n",
      " wt\n",
      " w=subsecretario\n",
      " nwt\n",
      " nw=general\n",
      " pw=al\n",
      " pw=digito\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      "Cluster 2:\n",
      " w=casos\n",
      " nw=por\n",
      " pw=digito\n",
      " pwu\n",
      " wu\n",
      " pw=<s>\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 3:\n",
      " w=categorías\n",
      " pw=las\n",
      " nw=de\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 4:\n",
      " wu\n",
      " pwu\n",
      " pw=digito\n",
      " w=digito\n",
      " nw=digito\n",
      " nwu\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      "Cluster 5:\n",
      " pw=consiguiente\n",
      " nw=el\n",
      " w=persistiría\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 6:\n",
      " pwu\n",
      " pw=digito\n",
      " nw=número\n",
      " w=del\n",
      " wu\n",
      " pw=<s>\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 7:\n",
      " nw=de\n",
      " pw=la\n",
      " w=función\n",
      " w=utilización\n",
      " pw=<s>\n",
      " nwu\n",
      " nwt\n",
      " nwd\n",
      " nw=vigentes\n",
      " wu\n",
      "Cluster 8:\n",
      " wt\n",
      " nw=lo\n",
      " w=por\n",
      " pw=<s>\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 9:\n",
      " w=las\n",
      " nw=observaciones\n",
      " pw=de\n",
      " wu\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 10:\n",
      " nw=tema\n",
      " w=el\n",
      " pw=con\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 11:\n",
      " pw=las\n",
      " nw=vigentes\n",
      " w=directrices\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 12:\n",
      " pw=febrero\n",
      " w=de\n",
      " nw=digito\n",
      " nwu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 13:\n",
      " pw=además\n",
      " pwt\n",
      " nw=traslado\n",
      " w=el\n",
      " nw=puedan\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=un\n",
      "Cluster 14:\n",
      " pw=el\n",
      " nw=comprendido\n",
      " w=período\n",
      " pw=administrativas\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 15:\n",
      " w=el\n",
      " pw=plenamente\n",
      " nw=examen\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 16:\n",
      " w=de\n",
      " nw=la\n",
      " pw=eficiencia\n",
      " pw=opinión\n",
      " wu\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 17:\n",
      " nw=reinserción\n",
      " pw=o\n",
      " w=la\n",
      " wu\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 18:\n",
      " nw=considerar\n",
      " pw=decisión\n",
      " w=de\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 19:\n",
      " nw=importante\n",
      " pw=otra\n",
      " w=función\n",
      " wu\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      " nw=vigentes\n",
      "Cluster 20:\n",
      " nw=para\n",
      " w=tiempo\n",
      " pw=con\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 21:\n",
      " pw=imperiosa\n",
      " nw=no\n",
      " w=que\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 22:\n",
      " wu\n",
      " nw=de\n",
      " w=digito\n",
      " pw=párrafo\n",
      " pw=digito\n",
      " pw=detalles\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 23:\n",
      " pw=fletamento\n",
      " nw=aeronaves\n",
      " w=de\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 24:\n",
      " nw=que\n",
      " w=adquisiciones\n",
      " pw=de\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 25:\n",
      " w=base\n",
      " nw=de\n",
      " pw=como\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 26:\n",
      " pw=detalles\n",
      " w=de\n",
      " nw=los\n",
      " wu\n",
      " pw=<s>\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      "Cluster 27:\n",
      " pw=que\n",
      " w=todos\n",
      " nw=los\n",
      " wu\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      " nw=vigentes\n",
      "Cluster 28:\n",
      " w=casos\n",
      " pw=los\n",
      " nw=de\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 29:\n",
      " w=siga\n",
      " nw=dando\n",
      " pw=que\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 30:\n",
      " nw=respecto\n",
      " w=con\n",
      " pw=porcentuales\n",
      " wu\n",
      " pw=además\n",
      " nw=reinserción\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 31:\n",
      " w=con\n",
      " nw=las\n",
      " pw=relación\n",
      " wu\n",
      " nw=que\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 32:\n",
      " w=mínimo\n",
      " pw=valor\n",
      " nw=de\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      " nw=vigentes\n",
      "Cluster 33:\n",
      " nw=examinar\n",
      " pw=contaba\n",
      " w=para\n",
      " pw=administrativas\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 34:\n",
      " pw=si\n",
      " w=se\n",
      " nw=justificaba\n",
      " wu\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 35:\n",
      " pw=y\n",
      " nw=de\n",
      " w=examen\n",
      " wu\n",
      " pw=además\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 36:\n",
      " pw=función\n",
      " nw=adquisición\n",
      " w=de\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 37:\n",
      " nw=nombramiento\n",
      " w=del\n",
      " pw=renovación\n",
      " wu\n",
      " nw=que\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n",
      "Cluster 38:\n",
      " nw=proceda\n",
      " w=cuando\n",
      " pw=administrativas\n",
      " pw=efectos\n",
      " pw=digito\n",
      " nw=reinserción\n",
      " nw=respecto\n",
      " pw=eficiencia\n",
      " nw=situación\n",
      " nw=tema\n",
      "Cluster 39:\n",
      " pw=indica\n",
      " w=que\n",
      " nw=en\n",
      " wu\n",
      " pw=administrativas\n",
      " nw=respecto\n",
      " nw=situación\n",
      " nw=tema\n",
      " nw=traslado\n",
      " nw=un\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "# order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(40):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
