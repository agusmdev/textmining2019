{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = ['-\\n\"Lo que sostiene a la pareja es el amor\"\\nClara Crespo (50) y Rodolfo Martínez (54) no se imaginan uno sin el otro.', '\"Prefiero ni pensarlo\", dice Clara.', 'Hace 26 años que están casados, y tienen cuatro hijas mujeres.', 'Se conocieron en el Ateneo Juventus, el movimiento juvenil de Capuchinos.', 'Hoy aseguran no estar sorprendidos del tiempo que llevan juntos sino de haber logrado entenderse tan bien.', '&#226;&#8364;&#8220;¿Qué les gusta y disgusta del otro?', '¿Qué quisieran cambiarle?', '&#226;&#8364;&#8220;Rodolfo: Me gusta que sea cariñosa, alegre y esté siempre pensando en mí, y que es una gran madre.', 'Me disgustaba que cuando se enojaba no quería hablar, pero ya no lo hace más.', 'A veces es indecisa pero ya me acostumbré.', 'No quiero cambiarle nada, que sea como es.', '&#226;&#8364;&#8220;Clara : Me gusta que es una persona emprendedora, alegre, optimista y servicial.', 'Me gustaría que a veces fuera más sutil para decir las cosas.', 'Pienso que las personas vamos cambiando con el tiempo de acuerdo a la edad, a las circunstancias que vivimos y todo lo que nos rodea.', 'Seguramente que no somos los mismos que cuando nos casamos y siempre seguiremos descubriendo cosas nuevas del otro.', 'Lo bueno es conversar y ayudarse a cambiar esas cosas que molestan al otro.', '&#226;&#8364;&#8220;¿Cuál fue el momento más difícil?', '-C: Sin duda fue cuando perdimos una hija.', 'Después de un dolor tan grande uno ve la vida de otra manera y ningún problema te parece tan grande.', 'Lo que más nos ayudó es que los dos compartimos la misma fe en Dios y sólo a través de &#195;&#8240;l podes darle otro sentido a la muerte.', 'También cuando vivimos separados un año y medio, por razones de trabajo de Rody.', 'Clara asegura que lo que sostiene a la pareja es el amor.', '\"Hay que alimentarlo para que crezca siempre.', 'Los proyectos y objetivos en común también ayudan a tener ilusiones y ganas de seguir juntos, pero todo es inútil si no hay amor.', 'Hay que tratar de crecer en todos los aspectos en forma permanente\".', '&#226;&#8364;&#8220;Un matrimonio a largo plazo, ¿es un refugio contra inseguridades, una rareza, un triunfo, orgullo?', '&#226;&#8364;&#8220;R: Es un medio para ser feliz, un proyecto de vida.', '&#226;&#8364;&#8220;C: Es una hermosa experiencia, más que todo eso.', 'El triunfo es ir logrando quererse cada día más.', '&#226;&#8364;&#8220;¿Por qué ahora las parejas duran menos?', '&#226;&#8364;&#8220;C: Creo que puede faltar comunicación y a veces proyecto y objetivos en común.', 'Cuando uno elige la vida de a dos a veces tiene que dejar de lado o postergar intereses personales.', '-¿Los recursos económicos son un conflicto?', '&#226;&#8364;&#8220;R: No son un problema, aunque a veces no había suficiente nunca fue una prioridad.', 'En general lo manejamos juntos, aunque el día a día lo lleva Clara.', '&#226;&#8364;&#8220;C: Siempre pusimos en común los ingresos cuando los dos trabajábamos.', 'Todo es de los dos.', '¡Menos mal, sino ahora que no trabajo estaría chau!', 'Y nos ponemos de acuerdo en la forma de administrarlo.', '&#226;&#8364;&#8220;¿La pasión es el secreto de la duración feliz?', 'R: La pasión es necesaria, pero no es el secreto de la felicidad.', 'Es importante mantener la pasión de los primeros años, toda la vida.', '-\\nEl Carbó y el Ipem 270 levantaron la toma\\nLos secundarios Ipem 270 Manuel Belgrano y Alejandro Carbó decidieron ayer levantar la toma de las instituciones escolares.', 'Así, se sumaron a la medida que ya había tomado el Jerónimo Luis de Cabrera el sábado.', 'Estos tres colegios habían iniciado la toma el miércoles 29 de septiembre en reclamo de mejoras edilicias y pidiendo que se discuta el anteproyecto de reforma de la ley de Educación.', 'El sábado, suscribieron un acuerdo con el Ministerio de Educación por el que levantaban las tomas a cambio de planes de obras de las y una instancia de debate para la normativa.', '\"Si el Gobierno nos toma el pelo, volveremos a las tomas\", advirtieron desde Secundarios Unidos de Córdoba, que aglutina a los centros de estudiantes de esas escuelas, al tiempo que calificaron lo logrado como \"una victoria\".', '\"Que sepan que cada día somos más y más colegios los que abrimos los ojos para luchar día a día por una educación para todos y todas\", agregan.', 'También firmaron el acuerdo el Deán Funes, el Nicolás Copérnico y el Ipem 16 de Villa Cornú, que en principio levantarían las tomas entre martes y miércoles, cuando lleguen los planes de obras.', 'No obstante, desde el grupo que mantiene las medidas de fuerza por el reclamo de la ley de Educación pusieron en duda esa posibilidad.', 'Ese grupo, denominado Coordinadora Interestudiantil, también volvió a llamar a la unidad del movimiento estudiantil.', '\"Convocamos a las escuelas que han firmado el acta porque se han empezado algunos de los planes de refacción a continuar las luchas\", sostuvieron.', '-\\n\"Tenemos una familia hermosa, qué más pedir\"\\nPedro (78) y Mary (74) parecen estar viviendo una luna de miel, pero llevan 51 años casados.', 'Pedro la trata como a una reina, de vez en cuando le compra bombones o la sorprende con una carta que algún locutor lee en la radio.', 'La llama \"Gordita\" a cada rato, la abraza y se ríen.', 'No han tenido una vida fácil, dicen.', 'Pero agradecen lo que les ha dado: cinco hijos (uno murió) y 13 nietos.', '\"Estamos juntos hace más de 21 mil días.', 'Hace 59 años que estamos de novios\", comenta con precisión Pedro Rodríguez, en su casa de barrio Ayacucho.', 'En la entrada del hogar que habitan hace 46 años, hay una Virgen y una leyenda que anticipa los cimientos con los que se construyó este hogar.', 'Dice más o menos así: \"Somos Pedro y Mary.', 'Tenemos una familia hermosa, qué más podemos pedir\".', 'Mary es María Isabel Barrionuevo, ex empleada de la Fábrica Militar de Aviones.', 'La mujer cuenta que se conocieron a los 13 años y todo lo que vino después.', 'La charla es tan amena que el agua para el café se consume por completo.', '\"Nada que ver con las relaciones de ahora.', 'A los dos meses de estar de novios, recién me dio el primer beso.', 'Yo lo paraba en seco\", recuerda Mary.', 'Sin embargo no cree que el tiempo pasado haya sido mejor.', '\"Había muchos tabúes\".', '&#226;&#8364;&#8220;¿Se imaginaron que iban a durar tanto tiempo?', '&#226;&#8364;&#8220;Uno no tuvo tiempo de analizar.', 'Nos casamos enamorados.', '¡No sabés lo que fue la luna de miel!', '¡Salir de noche solos!', 'Nunca habíamos salido solos&#226;&#8364;&#8220;, dice Mary, entre risas.', 'Coinciden en que son muy compañeros y saben conversar.', 'Todo lo hacen juntos.', '\"Pobrecito el que se quede cuando el otro desaparezca\", reflexiona Pedro, ex empleado de Entel.', '\"Mi madre me decía siempre que cuando en una discusión uno está nervioso, el otro se debe callar.', 'Hay que esperar que pare la tormenta y después hablar.', 'A nosotros nos ayudó\", aconseja Mary.', 'Pedro asegura que no han tenido tiempo para peleas; si había discusiones, era por los hijos.', '\"A veces uno salía en defensa de uno o de otro\", admiten.', 'Creen que los momentos más difíciles fueron los comienzos.', 'Los otros avatares de la vida los unió más.', '&#226;&#8364;&#8220;¿Qué les gusta del otro?', '&#226;&#8364;&#8220;&#195;&#8240;l es muy noble, honesto, siempre está tratando de ayudar, es sencillo y generoso, dice Mary, con mucha seguridad.', 'Pedro la mira, y responde: \"Me gusta todo, es inigualable\".', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import sklearn.manifold\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cleaning the corpus (. , ! ? ...)\n",
    "words = []\n",
    "for s in raw:\n",
    "    #s = re.sub(r\"\\d+\", \"NUM\", s)\n",
    "    corpus = re.sub(r\"[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑ]\", \" \", s)\n",
    "    corpus_sin_espacios = re.sub(' +',' ',corpus)\n",
    "    #corpus = corpus.lower()\n",
    "    #corpus = corpus.split()                              ----------> ojo \n",
    "    #corpus = re.findall(r'\\S+', corpus,flags = re.UNICODE)\n",
    "    words.append(corpus_sin_espacios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = []\n",
    "for sentence in words:\n",
    "    if sentence != ' ':\n",
    "        sent_list.append([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for sent in sent_list:\n",
    "    #print(sent[0])\n",
    "    aux = sent[0].split()\n",
    "    #print(aux)\n",
    "    if  len(aux[0]) == 1:\n",
    "        #print(aux[0])\n",
    "        if aux[0] not in {'A', 'Y', 'O'}:\n",
    "            #print(aux[0])\n",
    "            del aux[0]\n",
    "    final.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['-\\n\"Lo que sostiene a la pareja es el amor\"\\nClara Crespo (50) y Rodolfo Martínez (54) no se imaginan uno sin el otro.', '\"Prefiero ni pensarlo\", dice Clara.', 'Hace 26 años que están casados, y tienen cuatro hijas mujeres.', 'Se conocieron en el Ateneo Juventus, el movimiento juvenil de Capuchinos.', 'Hoy aseguran no estar sorprendidos del tiempo que llevan juntos sino de haber logrado entenderse tan bien.', '&#226;&#8364;&#8220;¿Qué les gusta y disgusta del otro?', '¿Qué quisieran cambiarle?', '&#226;&#8364;&#8220;Rodolfo: Me gusta que sea cariñosa, alegre y esté siempre pensando en mí, y que es una gran madre.', 'Me disgustaba que cuando se enojaba no quería hablar, pero ya no lo hace más.', 'A veces es indecisa pero ya me acostumbré.', 'No quiero cambiarle nada, que sea como es.', '&#226;&#8364;&#8220;Clara : Me gusta que es una persona emprendedora, alegre, optimista y servicial.', 'Me gustaría que a veces fuera más sutil para decir las cosas.', 'Pienso que las personas vamos cambiando con el tiempo de acuerdo a la edad, a las circunstancias que vivimos y todo lo que nos rodea.', 'Seguramente que no somos los mismos que cuando nos casamos y siempre seguiremos descubriendo cosas nuevas del otro.', 'Lo bueno es conversar y ayudarse a cambiar esas cosas que molestan al otro.', '&#226;&#8364;&#8220;¿Cuál fue el momento más difícil?', '-C: Sin duda fue cuando perdimos una hija.', 'Después de un dolor tan grande uno ve la vida de otra manera y ningún problema te parece tan grande.', 'Lo que más nos ayudó es que los dos compartimos la misma fe en Dios y sólo a través de &#195;&#8240;l podes darle otro sentido a la muerte.', 'También cuando vivimos separados un año y medio, por razones de trabajo de Rody.', 'Clara asegura que lo que sostiene a la pareja es el amor.', '\"Hay que alimentarlo para que crezca siempre.', 'Los proyectos y objetivos en común también ayudan a tener ilusiones y ganas de seguir juntos, pero todo es inútil si no hay amor.', 'Hay que tratar de crecer en todos los aspectos en forma permanente\".', '&#226;&#8364;&#8220;Un matrimonio a largo plazo, ¿es un refugio contra inseguridades, una rareza, un triunfo, orgullo?', '&#226;&#8364;&#8220;R: Es un medio para ser feliz, un proyecto de vida.', '&#226;&#8364;&#8220;C: Es una hermosa experiencia, más que todo eso.', 'El triunfo es ir logrando quererse cada día más.', '&#226;&#8364;&#8220;¿Por qué ahora las parejas duran menos?', '&#226;&#8364;&#8220;C: Creo que puede faltar comunicación y a veces proyecto y objetivos en común.', 'Cuando uno elige la vida de a dos a veces tiene que dejar de lado o postergar intereses personales.', '-¿Los recursos económicos son un conflicto?', '&#226;&#8364;&#8220;R: No son un problema, aunque a veces no había suficiente nunca fue una prioridad.', 'En general lo manejamos juntos, aunque el día a día lo lleva Clara.', '&#226;&#8364;&#8220;C: Siempre pusimos en común los ingresos cuando los dos trabajábamos.', 'Todo es de los dos.', '¡Menos mal, sino ahora que no trabajo estaría chau!', 'Y nos ponemos de acuerdo en la forma de administrarlo.', '&#226;&#8364;&#8220;¿La pasión es el secreto de la duración feliz?', 'R: La pasión es necesaria, pero no es el secreto de la felicidad.', 'Es importante mantener la pasión de los primeros años, toda la vida.', '-\\nEl Carbó y el Ipem 270 levantaron la toma\\nLos secundarios Ipem 270 Manuel Belgrano y Alejandro Carbó decidieron ayer levantar la toma de las instituciones escolares.', 'Así, se sumaron a la medida que ya había tomado el Jerónimo Luis de Cabrera el sábado.', 'Estos tres colegios habían iniciado la toma el miércoles 29 de septiembre en reclamo de mejoras edilicias y pidiendo que se discuta el anteproyecto de reforma de la ley de Educación.', 'El sábado, suscribieron un acuerdo con el Ministerio de Educación por el que levantaban las tomas a cambio de planes de obras de las y una instancia de debate para la normativa.', '\"Si el Gobierno nos toma el pelo, volveremos a las tomas\", advirtieron desde Secundarios Unidos de Córdoba, que aglutina a los centros de estudiantes de esas escuelas, al tiempo que calificaron lo logrado como \"una victoria\".', '\"Que sepan que cada día somos más y más colegios los que abrimos los ojos para luchar día a día por una educación para todos y todas\", agregan.', 'También firmaron el acuerdo el Deán Funes, el Nicolás Copérnico y el Ipem 16 de Villa Cornú, que en principio levantarían las tomas entre martes y miércoles, cuando lleguen los planes de obras.', 'No obstante, desde el grupo que mantiene las medidas de fuerza por el reclamo de la ley de Educación pusieron en duda esa posibilidad.', 'Ese grupo, denominado Coordinadora Interestudiantil, también volvió a llamar a la unidad del movimiento estudiantil.', '\"Convocamos a las escuelas que han firmado el acta porque se han empezado algunos de los planes de refacción a continuar las luchas\", sostuvieron.', '-\\n\"Tenemos una familia hermosa, qué más pedir\"\\nPedro (78) y Mary (74) parecen estar viviendo una luna de miel, pero llevan 51 años casados.', 'Pedro la trata como a una reina, de vez en cuando le compra bombones o la sorprende con una carta que algún locutor lee en la radio.', 'La llama \"Gordita\" a cada rato, la abraza y se ríen.', 'No han tenido una vida fácil, dicen.', 'Pero agradecen lo que les ha dado: cinco hijos (uno murió) y 13 nietos.', '\"Estamos juntos hace más de 21 mil días.', 'Hace 59 años que estamos de novios\", comenta con precisión Pedro Rodríguez, en su casa de barrio Ayacucho.', 'En la entrada del hogar que habitan hace 46 años, hay una Virgen y una leyenda que anticipa los cimientos con los que se construyó este hogar.', 'Dice más o menos así: \"Somos Pedro y Mary.', 'Tenemos una familia hermosa, qué más podemos pedir\".', 'Mary es María Isabel Barrionuevo, ex empleada de la Fábrica Militar de Aviones.', 'La mujer cuenta que se conocieron a los 13 años y todo lo que vino después.', 'La charla es tan amena que el agua para el café se consume por completo.', '\"Nada que ver con las relaciones de ahora.', 'A los dos meses de estar de novios, recién me dio el primer beso.', 'Yo lo paraba en seco\", recuerda Mary.', 'Sin embargo no cree que el tiempo pasado haya sido mejor.', '\"Había muchos tabúes\".', '&#226;&#8364;&#8220;¿Se imaginaron que iban a durar tanto tiempo?', '&#226;&#8364;&#8220;Uno no tuvo tiempo de analizar.', 'Nos casamos enamorados.', '¡No sabés lo que fue la luna de miel!', '¡Salir de noche solos!', 'Nunca habíamos salido solos&#226;&#8364;&#8220;, dice Mary, entre risas.', 'Coinciden en que son muy compañeros y saben conversar.', 'Todo lo hacen juntos.', '\"Pobrecito el que se quede cuando el otro desaparezca\", reflexiona Pedro, ex empleado de Entel.', '\"Mi madre me decía siempre que cuando en una discusión uno está nervioso, el otro se debe callar.', 'Hay que esperar que pare la tormenta y después hablar.', 'A nosotros nos ayudó\", aconseja Mary.', 'Pedro asegura que no han tenido tiempo para peleas; si había discusiones, era por los hijos.', '\"A veces uno salía en defensa de uno o de otro\", admiten.', 'Creen que los momentos más difíciles fueron los comienzos.', 'Los otros avatares de la vida los unió más.', '&#226;&#8364;&#8220;¿Qué les gusta del otro?', '&#226;&#8364;&#8220;&#195;&#8240;l es muy noble, honesto, siempre está tratando de ayudar, es sencillo y generoso, dice Mary, con mucha seguridad.', 'Pedro la mira, y responde: \"Me gusta todo, es inigualable\".', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2b6d88d170a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     text = f.read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     return [\n\u001b[1;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \"\"\"\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \"\"\"\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \"\"\"\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \"\"\"\n\u001b[1;32m   1361\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/textmining2019/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# with open('clean_corpus/spanish_billion_words/spanish_billion_words_10', 'r') as f:\n",
    "#     text = f.read()\n",
    "    \n",
    "words = nltk.word_tokenize(text)[:50000]\n",
    "# print(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "words = normalize(words[:500])\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "\n",
    "lemmas = lemmatize_verbs(words)\n",
    "# print('Stemmed:\\n', stems)\n",
    "# print('\\nLemmatized:\\n', lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec(final, min_count = 1, size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00131752, -0.01432324, -0.01093078, ..., -0.01034074,\n",
       "        -0.00308729,  0.00824945],\n",
       "       [-0.01343514,  0.01320515, -0.01136157, ...,  0.00307553,\n",
       "         0.00792028,  0.00474973],\n",
       "       [-0.01333705, -0.00327786, -0.01880427, ...,  0.00479359,\n",
       "         0.01337885,  0.00101845],\n",
       "       ...,\n",
       "       [-0.00745198, -0.00158709, -0.00051782, ...,  0.008443  ,\n",
       "         0.01426587, -0.01382852],\n",
       "       [ 0.00151626, -0.00577545,  0.01391323, ...,  0.00670677,\n",
       "         0.00530546, -0.00977991],\n",
       "       [-0.01427732, -0.00292806, -0.01056713, ...,  0.00632687,\n",
       "        -0.00482501, -0.00309228]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv.vectors\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 40\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "\n",
    "kmeans_clustering = KMeans(n_clusters = num_clusters )\n",
    "\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "\n",
    "word_centroid_map = dict(zip(model.wv.index2word, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {18: {'A',\n",
       "              'Clara',\n",
       "              'Entel',\n",
       "              'Había',\n",
       "              'Jerónimo',\n",
       "              'Somos',\n",
       "              'administrarlo',\n",
       "              'alimentarlo',\n",
       "              'avatares',\n",
       "              'de',\n",
       "              'discuta',\n",
       "              'firmado',\n",
       "              'haber',\n",
       "              'ir',\n",
       "              'lo',\n",
       "              'medidas',\n",
       "              'medio',\n",
       "              'mí',\n",
       "              'pareja',\n",
       "              'pensando',\n",
       "              'persona',\n",
       "              'personas',\n",
       "              'salido',\n",
       "              'y'},\n",
       "             0: {'Carbó',\n",
       "              'Es',\n",
       "              'Funes',\n",
       "              'Ministerio',\n",
       "              'Pero',\n",
       "              'También',\n",
       "              'Yo',\n",
       "              'acuerdo',\n",
       "              'aspectos',\n",
       "              'ayudó',\n",
       "              'cambiando',\n",
       "              'cambiarle',\n",
       "              'cinco',\n",
       "              'comenta',\n",
       "              'firmaron',\n",
       "              'generoso',\n",
       "              'hablar',\n",
       "              'hay',\n",
       "              'hogar',\n",
       "              'imaginan',\n",
       "              'les',\n",
       "              'levantar',\n",
       "              'mil',\n",
       "              'optimista',\n",
       "              'orgullo',\n",
       "              'que',\n",
       "              'razones',\n",
       "              'tanto',\n",
       "              'un',\n",
       "              'viviendo'},\n",
       "             1: {'Cornú',\n",
       "              'Dios',\n",
       "              'Hoy',\n",
       "              'Juventus',\n",
       "              'Martínez',\n",
       "              'María',\n",
       "              'casamos',\n",
       "              'debate',\n",
       "              'decía',\n",
       "              'duda',\n",
       "              'el',\n",
       "              'elige',\n",
       "              'fácil',\n",
       "              'ha',\n",
       "              'indecisa',\n",
       "              'la',\n",
       "              'obstante',\n",
       "              'precisión',\n",
       "              'principio',\n",
       "              'recursos',\n",
       "              'sido',\n",
       "              'suscribieron',\n",
       "              'tomas',\n",
       "              'vida'},\n",
       "             9: {'Convocamos',\n",
       "              'Estos',\n",
       "              'Pedro',\n",
       "              'Que',\n",
       "              'a',\n",
       "              'difíciles',\n",
       "              'dio',\n",
       "              'económicos',\n",
       "              'hijos',\n",
       "              'llevan',\n",
       "              'por',\n",
       "              'pusieron',\n",
       "              'pusimos'},\n",
       "             12: {'Belgrano',\n",
       "              'Nunca',\n",
       "              'acostumbré',\n",
       "              'admiten',\n",
       "              'aglutina',\n",
       "              'asegura',\n",
       "              'chau',\n",
       "              'como',\n",
       "              'entenderse',\n",
       "              'es',\n",
       "              'hace',\n",
       "              'levantaron',\n",
       "              'los',\n",
       "              'luchar',\n",
       "              'martes',\n",
       "              'momentos',\n",
       "              'murió',\n",
       "              'otra',\n",
       "              'parece',\n",
       "              'pedir',\n",
       "              'planes',\n",
       "              'proyectos',\n",
       "              'reclamo',\n",
       "              'sencillo',\n",
       "              'su',\n",
       "              'trata',\n",
       "              'través'},\n",
       "             19: {'calificaron',\n",
       "              'casa',\n",
       "              'en',\n",
       "              'juvenil',\n",
       "              'podes',\n",
       "              'tomado',\n",
       "              'tuvo'},\n",
       "             32: {'Creo',\n",
       "              'Lo',\n",
       "              'Mi',\n",
       "              'Secundarios',\n",
       "              'acta',\n",
       "              'inútil',\n",
       "              'más',\n",
       "              'noble',\n",
       "              'ojos',\n",
       "              'otro',\n",
       "              'somos',\n",
       "              'tienen',\n",
       "              'una',\n",
       "              'volvió'},\n",
       "             26: {'Ese',\n",
       "              'Manuel',\n",
       "              'conocieron',\n",
       "              'dado',\n",
       "              'esa',\n",
       "              'experiencia',\n",
       "              'gran',\n",
       "              'largo',\n",
       "              'las',\n",
       "              'mismos',\n",
       "              'mujer',\n",
       "              'nietos',\n",
       "              'secundarios',\n",
       "              'seguir',\n",
       "              'solos',\n",
       "              'vamos',\n",
       "              've',\n",
       "              'vino'},\n",
       "             25: {'Fábrica',\n",
       "              'Nada',\n",
       "              'Rodríguez',\n",
       "              'común',\n",
       "              'del',\n",
       "              'fe',\n",
       "              'inseguridades',\n",
       "              'no',\n",
       "              'quería'},\n",
       "             13: {'Por',\n",
       "              'abrimos',\n",
       "              'logrado',\n",
       "              'mujeres',\n",
       "              'nada',\n",
       "              'proyecto',\n",
       "              'se',\n",
       "              'tratar',\n",
       "              'victoria'},\n",
       "             10: {'Barrionuevo',\n",
       "              'Coordinadora',\n",
       "              'Isabel',\n",
       "              'Seguramente',\n",
       "              'Siempre',\n",
       "              'Todo',\n",
       "              'compra',\n",
       "              'cuando',\n",
       "              'descubriendo',\n",
       "              'edad',\n",
       "              'había',\n",
       "              'inigualable',\n",
       "              'podemos',\n",
       "              'puede',\n",
       "              'seguridad',\n",
       "              'servicial'},\n",
       "             22: {'Gordita',\n",
       "              'consume',\n",
       "              'decidieron',\n",
       "              'estudiantil',\n",
       "              'logrando',\n",
       "              'manera',\n",
       "              'mantiene',\n",
       "              'para',\n",
       "              'perdimos',\n",
       "              'primer',\n",
       "              'sorprendidos',\n",
       "              'sumaron'},\n",
       "             14: {'Capuchinos',\n",
       "              'Qué',\n",
       "              'Y',\n",
       "              'charla',\n",
       "              'desde',\n",
       "              'edilicias',\n",
       "              'embargo',\n",
       "              'enojaba',\n",
       "              'ganas',\n",
       "              'hijas',\n",
       "              'honesto',\n",
       "              'lleguen',\n",
       "              'lleva',\n",
       "              'medida',\n",
       "              'personales',\n",
       "              'quede',\n",
       "              'recuerda',\n",
       "              'sólo',\n",
       "              'también',\n",
       "              'uno'},\n",
       "             29: {'Ipem',\n",
       "              'alegre',\n",
       "              'ayudarse',\n",
       "              'feliz',\n",
       "              'gusta',\n",
       "              'haya',\n",
       "              'instituciones',\n",
       "              'llamar',\n",
       "              'movimiento',\n",
       "              'mucha',\n",
       "              'pidiendo',\n",
       "              'tiempo'},\n",
       "             39: {'Militar',\n",
       "              'Rody',\n",
       "              'café',\n",
       "              'con',\n",
       "              'contra',\n",
       "              'eso',\n",
       "              'felicidad',\n",
       "              'hacen',\n",
       "              'nervioso',\n",
       "              'salía',\n",
       "              'toma',\n",
       "              'tres'},\n",
       "             8: {'Coinciden',\n",
       "              'Copérnico',\n",
       "              'Dice',\n",
       "              'Mary',\n",
       "              'Rodolfo',\n",
       "              'año',\n",
       "              'bombones',\n",
       "              'callar',\n",
       "              'carta',\n",
       "              'casados',\n",
       "              'disgustaba',\n",
       "              'ex',\n",
       "              'fuera',\n",
       "              'levantarían',\n",
       "              'meses',\n",
       "              'muchos',\n",
       "              'nos',\n",
       "              'parecen',\n",
       "              'seguiremos',\n",
       "              'ver'},\n",
       "             2: {'Nicolás',\n",
       "              'así',\n",
       "              'años',\n",
       "              'entre',\n",
       "              'habían',\n",
       "              'normativa',\n",
       "              'recién',\n",
       "              'te'},\n",
       "             23: {'Pienso',\n",
       "              'Virgen',\n",
       "              'al',\n",
       "              'analizar',\n",
       "              'dolor',\n",
       "              'están',\n",
       "              'matrimonio',\n",
       "              'veces'},\n",
       "             15: {'Estamos',\n",
       "              'agradecen',\n",
       "              'agregan',\n",
       "              'aseguran',\n",
       "              'cariñosa',\n",
       "              'comienzos',\n",
       "              'crecer',\n",
       "              'crezca',\n",
       "              'dejar',\n",
       "              'duran',\n",
       "              'durar',\n",
       "              'día',\n",
       "              'esas',\n",
       "              'esperar',\n",
       "              'hermosa',\n",
       "              'luna',\n",
       "              'mantener',\n",
       "              'miel',\n",
       "              'nuevas',\n",
       "              'parejas',\n",
       "              'reina',\n",
       "              'responde',\n",
       "              'rodea',\n",
       "              'sea',\n",
       "              'toda',\n",
       "              'todo',\n",
       "              'tratando'},\n",
       "             28: {'algunos',\n",
       "              'empezado',\n",
       "              'este',\n",
       "              'juntos',\n",
       "              'mira',\n",
       "              'permanente',\n",
       "              'sábado'},\n",
       "             20: {'Ateneo',\n",
       "              'Ayacucho',\n",
       "              'Me',\n",
       "              'agua',\n",
       "              'ayudan',\n",
       "              'completo',\n",
       "              'escuelas',\n",
       "              'fue',\n",
       "              'general',\n",
       "              'l',\n",
       "              'pare',\n",
       "              'quererse',\n",
       "              'refacción',\n",
       "              'reflexiona',\n",
       "              'separados',\n",
       "              'sorprende'},\n",
       "             37: {'Después',\n",
       "              'Sin',\n",
       "              'amor',\n",
       "              'cambiar',\n",
       "              'cambio',\n",
       "              'denominado',\n",
       "              'esté',\n",
       "              'fuerza',\n",
       "              'grande',\n",
       "              'iniciado',\n",
       "              'mejoras',\n",
       "              'miércoles',\n",
       "              'pasión',\n",
       "              'ponemos',\n",
       "              'siempre',\n",
       "              'ya'},\n",
       "             31: {'No',\n",
       "              'anticipa',\n",
       "              'colegios',\n",
       "              'comunicación',\n",
       "              'conflicto',\n",
       "              'cosas',\n",
       "              'emprendedora',\n",
       "              'familia',\n",
       "              'iban',\n",
       "              'mal',\n",
       "              'necesaria',\n",
       "              'pero',\n",
       "              'postergar',\n",
       "              'quiero',\n",
       "              'rato',\n",
       "              'ríen',\n",
       "              'sabés',\n",
       "              'suficiente',\n",
       "              'tan',\n",
       "              'vivimos'},\n",
       "             38: {'Creen',\n",
       "              'Pobrecito',\n",
       "              'algún',\n",
       "              'beso',\n",
       "              'centros',\n",
       "              'cuatro',\n",
       "              'dos',\n",
       "              'empleada',\n",
       "              'luchas',\n",
       "              'momento',\n",
       "              'radio',\n",
       "              'tiene',\n",
       "              'trabajábamos'},\n",
       "             4: {'Cuando',\n",
       "              'Hace',\n",
       "              'Interestudiantil',\n",
       "              'La',\n",
       "              'Se',\n",
       "              'abraza',\n",
       "              'ayudar',\n",
       "              'circunstancias',\n",
       "              'cree',\n",
       "              'duración',\n",
       "              'empleado',\n",
       "              'enamorados',\n",
       "              'estamos',\n",
       "              'levantaban',\n",
       "              'ley',\n",
       "              'molestan',\n",
       "              'qué',\n",
       "              'risas',\n",
       "              'sostiene',\n",
       "              'trabajo'},\n",
       "             7: {'Gobierno',\n",
       "              'Los',\n",
       "              'cimientos',\n",
       "              'discusiones',\n",
       "              'días',\n",
       "              'está',\n",
       "              'hija',\n",
       "              'ilusiones',\n",
       "              'llama',\n",
       "              'noche',\n",
       "              'sepan',\n",
       "              'sin',\n",
       "              'son',\n",
       "              'todos'},\n",
       "             17: {'Aviones',\n",
       "              'El',\n",
       "              'Unidos',\n",
       "              'advirtieron',\n",
       "              'compartimos',\n",
       "              'cuenta',\n",
       "              'darle',\n",
       "              'forma',\n",
       "              'gustaría',\n",
       "              'instancia',\n",
       "              'intereses',\n",
       "              'o',\n",
       "              'paraba',\n",
       "              'pasado',\n",
       "              'sentido',\n",
       "              'septiembre',\n",
       "              'sostuvieron'},\n",
       "             11: {'Educación', 'después', 'han', 'menos', 'ni', 'prioridad'},\n",
       "             5: {'Deán',\n",
       "              'bien',\n",
       "              'cada',\n",
       "              'desaparezca',\n",
       "              'dice',\n",
       "              'habitan',\n",
       "              'primeros',\n",
       "              'seco',\n",
       "              'tener'},\n",
       "             16: {'compañeros',\n",
       "              'difícil',\n",
       "              'disgusta',\n",
       "              'escolares',\n",
       "              'estar',\n",
       "              'leyenda',\n",
       "              'nosotros',\n",
       "              'nunca',\n",
       "              'problema',\n",
       "              'reforma',\n",
       "              'unió'},\n",
       "             30: {'Si',\n",
       "              'ahora',\n",
       "              'locutor',\n",
       "              'madre',\n",
       "              'manejamos',\n",
       "              'me',\n",
       "              'novios',\n",
       "              'posibilidad',\n",
       "              'ser',\n",
       "              'si',\n",
       "              'sutil'},\n",
       "             6: {'Hay',\n",
       "              'Luis',\n",
       "              'anteproyecto',\n",
       "              'construyó',\n",
       "              'era',\n",
       "              'fueron',\n",
       "              'lado',\n",
       "              'plazo',\n",
       "              'relaciones',\n",
       "              'tabúes',\n",
       "              'tormenta',\n",
       "              'vez'},\n",
       "             34: {'Alejandro',\n",
       "              'Así',\n",
       "              'Cuál',\n",
       "              'conversar',\n",
       "              'debe',\n",
       "              'obras',\n",
       "              'sino',\n",
       "              'volveremos'},\n",
       "             3: {'Salir',\n",
       "              'Un',\n",
       "              'aunque',\n",
       "              'continuar',\n",
       "              'dicen',\n",
       "              'mejor',\n",
       "              'objetivos',\n",
       "              'quisieran'},\n",
       "             27: {'En',\n",
       "              'Villa',\n",
       "              'aconseja',\n",
       "              'entrada',\n",
       "              'estaría',\n",
       "              'habíamos',\n",
       "              'imaginaron',\n",
       "              'lee',\n",
       "              'ningún',\n",
       "              'refugio',\n",
       "              'todas',\n",
       "              'triunfo'},\n",
       "             33: {'Córdoba',\n",
       "              'Prefiero',\n",
       "              'Tenemos',\n",
       "              'ayer',\n",
       "              'discusión',\n",
       "              'faltar',\n",
       "              'pensarlo',\n",
       "              'saben',\n",
       "              'secreto'},\n",
       "             35: {'decir',\n",
       "              'defensa',\n",
       "              'grupo',\n",
       "              'le',\n",
       "              'misma',\n",
       "              'muerte',\n",
       "              'rareza',\n",
       "              'tenido',\n",
       "              'unidad'},\n",
       "             24: {'Crespo',\n",
       "              'importante',\n",
       "              'ingresos',\n",
       "              'muy',\n",
       "              'peleas',\n",
       "              'porque'},\n",
       "             36: {'Cabrera', 'Nos', 'Uno', 'bueno', 'estudiantes', 'otros'},\n",
       "             21: {'Menos', 'amena', 'barrio', 'educación', 'pelo'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "res = defaultdict(set)\n",
    "for key, value in word_centroid_map.items():\n",
    "    res[value].add(key)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1)],\n",
       " [(1, 1), (5, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
       " [(0, 1), (1, 1), (5, 2), (8, 1), (14, 1), (15, 1)],\n",
       " [(5, 1),\n",
       "  (10, 1),\n",
       "  (13, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1)],\n",
       " [(1, 3),\n",
       "  (10, 1),\n",
       "  (15, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\n",
    "    \"La Corte Suprema de Justicia declaró inconstitucional la medida\",\n",
    "    \"El Máximo Tribunal de la Nación denegó la apelación\",\n",
    "    \"La corte de casación avaló la apelación\",\n",
    "    \"El Poder Ejecutivo Nacional apelará a la decisión del Tribunal\",\n",
    "    \"El recurso de casación fue dado de baja por falta de mérito\"\n",
    "]\n",
    "\n",
    "tokenized_documents = [\n",
    "    [word for word in document.lower().split()] for document in documents\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "corpus = [dictionary.doc2bow(tdoc) for tdoc in tokenized_documents]\n",
    "# corpus_features = set(word for tdoc in tokenized_documents for word in tdoc)\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus)\n",
    "# index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(corpus_features))\n",
    "\n",
    "# similarities = index[tfidf[corpus[0]]]\n",
    "# print(sorted(list(enumerate(similarities)), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "       n_clusters=40, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_clusters = 40\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "model = KMeans(n_clusters=number_of_clusters, \n",
    "               init='k-means++', \n",
    "               max_iter=100, # Maximum number of iterations of the k-means algorithm for a single run.\n",
    "               n_init=1)  # Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " su\n",
      " se\n",
      " digito\n",
      " web\n",
      " lo\n",
      " informacion\n",
      " si\n",
      " todo\n",
      " al\n",
      " esta\n",
      "Cluster 1:\n",
      " en\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 2:\n",
      " la\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 3:\n",
      " de\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 4:\n",
      " tribu\n",
      " zonas\n",
      " encuentra\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      "Cluster 5:\n",
      " el\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 6:\n",
      " las\n",
      " zonas\n",
      " entiendo\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 7:\n",
      " una\n",
      " enteramente\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 8:\n",
      " psiquico\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 9:\n",
      " que\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 10:\n",
      " por\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 11:\n",
      " taz\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 12:\n",
      " estado\n",
      " zonas\n",
      " encuentra\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      "Cluster 13:\n",
      " sus\n",
      " zonas\n",
      " entiendo\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 14:\n",
      " para\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 15:\n",
      " roanoke\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 16:\n",
      " los\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 17:\n",
      " puede\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 18:\n",
      " como\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 19:\n",
      " decir\n",
      " enteramente\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 20:\n",
      " un\n",
      " zonas\n",
      " encuentra\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      "Cluster 21:\n",
      " ahora\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 22:\n",
      " mas\n",
      " zonas\n",
      " entiendo\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 23:\n",
      " del\n",
      " encuentre\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 24:\n",
      " red\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 25:\n",
      " antired\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 26:\n",
      " cada\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 27:\n",
      " sentido\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 28:\n",
      " es\n",
      " enteramente\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 29:\n",
      " pero\n",
      " enteramente\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 30:\n",
      " mundo\n",
      " encuentro\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      " ensenaron\n",
      "Cluster 31:\n",
      " etc\n",
      " enteramente\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 32:\n",
      " deseo\n",
      " zonas\n",
      " entonces\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      "Cluster 33:\n",
      " propia\n",
      " zonas\n",
      " encuentra\n",
      " encuentro\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      "Cluster 34:\n",
      " misma\n",
      " zonas\n",
      " entonces\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      " enriquecer\n",
      " ensenaron\n",
      "Cluster 35:\n",
      " tiende\n",
      " zonas\n",
      " enteramente\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 36:\n",
      " todos\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 37:\n",
      " con\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 38:\n",
      " sino\n",
      " zonas\n",
      " encuentre\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n",
      "Cluster 39:\n",
      " ni\n",
      " zonas\n",
      " entiendo\n",
      " enemigos\n",
      " energeticos\n",
      " energia\n",
      " enfatiza\n",
      " enfrentados\n",
      " enormes\n",
      " enraizado\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_clusters):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "count = defaultdict(int)\n",
    "\n",
    "for word in sents:\n",
    "    count[word] += 1sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palabras más frecuentes: [('de', 4458), ('DIGITO', 3504), ('la', 2165), ('y', 1535), ('en', 1385), ('el', 1308), ('que', 1156), ('los', 1044), ('a', 955), ('las', 849)]\n",
      "Vocabulario: 5937\n",
      "Tokens: 50000\n"
     ]
    }
   ],
   "source": [
    "print('10 palabras más frecuentes:', sorted(count.items(), key=lambda x: -x[1])[:10])\n",
    "print('Vocabulario:', len(count))\n",
    "print('Tokens:', sum(count.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components for features reduction\n",
    "n_components = 5\n",
    "\n",
    "# number of clusters we want\n",
    "n_clusters = 5\n",
    "\n",
    "# covert words into TFIDF metrics\n",
    "tfidf = TfidfVectorizer()\n",
    "X_text = tfidf.fit_transform(sents)\n",
    "\n",
    "# reduce dimensions\n",
    "svd = TruncatedSVD(n_components=n_components, random_state = 0)\n",
    "X_2d = svd.fit_transform(X_text)\n",
    "\n",
    "# fit k-mean clustering\n",
    "model = KMeans(n_clusters=n_clusters, random_state = 0).fit(X_2d)\n",
    "\n",
    "# # predict our clusters for each song\n",
    "# X_clustered = kmeans.fit_predict(X_2d)\n",
    "\n",
    "# # display by groups\n",
    "# df_plot = pd.DataFrame(list(X_2d), list(X_clustered))\n",
    "# df_plot = df_plot.reset_index()\n",
    "# df_plot.rename(columns = {'index': 'Cluster'}, inplace = True)\n",
    "# df_plot['Cluster'] = df_plot['Cluster'].astype(int)\n",
    "\n",
    "# print(df_plot.head())\n",
    "\n",
    "# print(df_plot.groupby('Cluster').agg({'Cluster': 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f406b8952cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0morder_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
